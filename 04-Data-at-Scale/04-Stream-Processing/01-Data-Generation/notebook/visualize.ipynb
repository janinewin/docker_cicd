{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate a timeseries, let's thake a mean value and add a random noise dependanting on the standard deviation\n",
    "for the purpose of this challenge, we have provided plausible values for each sensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensorNames = ['AtmP','Temp','Airtight','H2OC']\n",
    "sensorCenterLines = [989.21,9.45,1216.02,9.64]\n",
    "standardDeviation = [8.35,8.42,39.98,4.23]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our use case, we need data that contain the following informations:\n",
    "- sensor: sensor name\n",
    "- reading: the value sent by the sensor\n",
    "- timeStamp: the time that the value has been sent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create a dataframe with the data, we can execute this code that generate 100 points for each 4 sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_sensors = []\n",
    "time_stamp_start = datetime.datetime(2022,11,25,9,0,0)\n",
    "time_step = datetime.timedelta(seconds=1)\n",
    "for i in range(100):\n",
    "    for pos in range(0,4):\n",
    "        l_sensors.append({\n",
    "            'sensor': sensorNames[pos],\n",
    "            'reading':np.random.normal(loc=sensorCenterLines[pos], scale=standardDeviation[pos]),\n",
    "            'timeStamp':time_stamp_start + i* time_step\n",
    "        })\n",
    "        \n",
    "df_sensors = pd.DataFrame(l_sensors)\n",
    "df_sensors.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data let's aggragate the values by timestamp(index) and by sensor(columns)\n",
    "for that you can use pandas.pivot_table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datas = pd.pivot_table(df_sensors,values = 'reading',index=\"timeStamp\",columns=\"sensor\",aggfunc='mean')\n",
    "df_datas.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot now the different sensors values by timeStamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datas.plot(subplots = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Latency"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real life, sensors are not synchronised together and they experience sometimes latency to send signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = 0, 0.2 # mean and standard deviation\n",
    "s = np.abs(np.random.normal(mu, sigma, 1000))\n",
    "\n",
    "plt.hist(s);\n",
    "plt.title('Possible latency distibution in sec'),\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_sensors_latency = []\n",
    "for i in range(1500):\n",
    "    for pos in range(0,4):\n",
    "        l_sensors_latency.append({\n",
    "            'sensor': sensorNames[pos],\n",
    "            'reading':np.random.normal(loc=sensorCenterLines[pos], scale=standardDeviation[pos]),\n",
    "            'timeStamp':time_stamp_start + i* time_step + datetime.timedelta(seconds=abs(random.gauss(0,0.2)))\n",
    "        })\n",
    "        \n",
    "df_sensors_latency = pd.DataFrame(l_sensors_latency)\n",
    "df_sensors_latency.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datas_latency = pd.pivot_table(df_sensors_latency,values = 'reading',index=\"timeStamp\",columns=\"sensor\",aggfunc='mean')\n",
    "df_datas_latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datas_latency.plot(subplots = True);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’¡ We can not gather the data continuously anymore because the data is not available for each sensor at the same time!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that case it is better to group the data in **fix windows** of 15s for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas, we can resample the timestamp index. This operation will be done in apache beam in the next challenge.\n",
    "We won't use pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datas_latency = df_datas_latency.resample('15s').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datas_latency.plot(subplots=True);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
