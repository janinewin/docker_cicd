{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1Ô∏è‚É£ Vectorize \"easy\" operations with pandas and numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Vectorized-addition.gif/220px-Vectorized-addition.gif'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 5000\n",
    "n_cols = 5000\n",
    "a = np.random.randint(low=0, high=5, size=(n_rows,n_cols), dtype=np.int64)\n",
    "df = pd.DataFrame(a)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider different methods for summing all elements of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Worse case scenario: double python for loop (O(n^2)) !!\n",
    "sum = 0\n",
    "for row_id in range(n_rows):\n",
    "    for el in a[row_id,:]:\n",
    "        sum = sum + el\n",
    "sum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Column-wise operation (axis=0): Apply np.sum 5000 times for each columns, then apply np.sum one last time to get the final result!\n",
    "np.apply_along_axis(np.sum, 0, a).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Row-wise operation (axis=1): Apply np.sum 5000 times for rows columns, then apply np.sum one last time to get the final result!\n",
    "np.apply_along_axis(np.sum, 1, a).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è Numpy is row-major (by default). Avoid iterating on its columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://craftofcoding.files.wordpress.com/2017/02/rowcolumnarrays.jpg?w=620&h=356'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, we can change its numpy's storage format from row to columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a           = np.ones((n_rows,n_cols), order='C') # C-style BY DEFAULT\n",
    "a_col_major = np.ones((n_rows,n_cols), order='F') # F for Fortran style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Column-wise operation\n",
    "np.apply_along_axis(np.sum, 0, a_col_major).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Row-wise operation\n",
    "np.apply_along_axis(np.sum, 1, a_col_major).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2)üêº Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Using pandas vectorized sum is much faster (here, it is called n_cols + 1 times)\n",
    "df.sum().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è**Pandas is column-major**. **Avoid iterating manually on its rows** (convert to numpy which is row-major if needs be)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column named \"0\", 1000 times\n",
    "%timeit -n1000 df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first ROW, 1000 times\n",
    "%timeit -n1000 df.iloc[0,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) What about more complex operations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "A_list = np.random.randint(0, 4, N)\n",
    "B_list = np.random.randint(0, 4, N)\n",
    "df = pd.DataFrame({'A': A_list, 'B': B_list})\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we want to do divide col \"A\" by col \"B\" in the following matrix, but without any `NaN`  \n",
    "\n",
    "Remember, in numpy\n",
    "- `1./0. == np.inf` ‚úÖ\n",
    "- but `0./0. == np.nan` üò∞\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# This would be super fast but it's not what we want!\n",
    "_ = df['A']/df['B']\n",
    "_.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define our custom division function\n",
    "\n",
    "def divide_without_nan(row):\n",
    "    if row[0] == row[1]:\n",
    "        return 1\n",
    "    return float(row[0]/row[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could \"apply\" on each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new = df.apply(lambda row: divide_without_nan(row), axis=1)\n",
    "assert new.isna().sum() == 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Remember, we need to try to avoid looping over pandas rows.\n",
    "\n",
    "‚ùì**Try to make it faster by converting to it to numpy first** (which is row-major), then use `np.apply_along_axis()`!\n",
    "You should find it's about 4 time faster!\n",
    "\n",
    "<details>\n",
    "  <summary markdown='span'>üéÅ Solution</summary>\n",
    "\n",
    "```python\n",
    "%%time\n",
    "new = np.apply_along_axis(divide_without_nan, 1, df.values)\n",
    "assert np.isnan(new).sum() == 0\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are still very very far from the purely \"vectorized\" speed offered by C-based numpy/pandas operation!  \n",
    "‚ùì **Can you find a way to make this computation fully vectorized ?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary markdown='span'>üí°Hints</summary>\n",
    "\n",
    "`np.where()`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2Ô∏è‚É£ When you can't find \"vectorized\" numpy equivalents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://wagon-public-datasets.s3.amazonaws.com/taxi-fare-ny/train_500k.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, asin, sqrt\n",
    "EARTH_RADIUS = 6371\n",
    "\n",
    "def haversine(lon1: float,lat1: float,lon2: float,lat2: float) -> float:\n",
    "    \"\"\"returns the geodistance in km between two tuple of coordinates\"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    return 2 * EARTH_RADIUS * asin(sqrt(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Baseline score: python loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "distances = df.apply(lambda row: haversine(row[\"pickup_longitude\"], row[\"pickup_latitude\"], row[\"dropoff_longitude\"], row[\"dropoff_latitude\"]), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üòµ What did we just do! Iterating on DataFrame by rows is a very bad practice...\n",
    "\n",
    "üëá We can do a bit better by transposing dataframe and iterate on its **columns**..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_coor = df[[\"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"]]\n",
    "distances = df_coor.T.apply(lambda col: haversine(*col), axis=0, raw=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we're still applying a non-vectorized lambda function, so pandas/numpy are not helping at all!\n",
    "\n",
    "Let's get rid of pandas and numpy overhead altogether and see what happens in pure python..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_loop_python(coordinates: list) -> list:\n",
    "    distances = np.zeros(len(coordinates))\n",
    "    for i, row in enumerate(coordinates):\n",
    "        distance = haversine(*row)\n",
    "        distances[i] = distance\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time distances = haversine_loop_python(list(df_coor.values))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Better, but still way too long! Basically, **a for loop in python is almost always sub-optimal**\n",
    "\n",
    "Let's vectorize this code!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Numba"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first option: `jit` your outer python loop directly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have a particular function to optimize, but a whole code block with python loops, you can use `@jit` to let numba try to create a optimized version of your whole code block the first time it runs. Then, all subsquent runs will be vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def haversine_loop_jit(coordinates):\n",
    "    distances = np.zeros(len(coordinates))\n",
    "    for i, row in enumerate(coordinates):\n",
    "        lon1, lat1, lon2, lat2 = map(radians, [row[0], row[1], row[2], row[3]])\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "        a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "        distance = 2 * EARTH_RADIUS * asin(sqrt(a))\n",
    "        distances[i] = distance\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this twice\n",
    "%time distances = haversine_loop_jit(df_coor.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Amazing, isn't it! Another 10x improvement here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### second option: `vectorize` your inner scalar computation, then call it with numpy arrays instead of scalars!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntax is simply \n",
    "\n",
    "```python\n",
    "@vectorize([output_type(arg1_type, arg2_type...)])\n",
    "def my_vectorized_python_function(arg1, arg2..):\n",
    "    pass\n",
    "```\n",
    "‚òùÔ∏è You just have to specify to numba what are the input and output type you expect, and the **new function can now take iterables** like pd.Series or np.ndarray instead of scalar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import vectorize, float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize([float64(float64, float64, float64, float64)])\n",
    "def vectorized_haversine(lon1,lat1,lon2,lat2):\n",
    "    \"\"\"returns the geodistance in km between two tuple of coordinates\"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    return 2 * EARTH_RADIUS * asin(sqrt(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell twice to see best speed performance\n",
    "%time distances = vectorized_haversine(df[\"pickup_longitude\"], df[\"pickup_latitude\"], df[\"dropoff_longitude\"], df[\"dropoff_latitude\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you had multiple CPUs or GPUs, you could go even faster with \n",
    "\n",
    "```python\n",
    "@vectorize(target=\"parallel\") # Multi-core CPU\n",
    "@vectorize(target=\"CUDA\") # GPU acceleration\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üì∫ If you are not convinced yet, take 5min to see [this real-world example](https://youtu.be/x58W9A2lnQc?t=719) on youtube"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) Cython"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you know how to write C, you can also code your own vectorized function using Cython. The goal is to minimize the amount of \"python\" code (in yellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "\n",
    "from libc.math cimport sin, cos, asin, sqrt\n",
    "   \n",
    "## Equivalent to 3.1415927 / 180\n",
    "cdef float PI_RATIO = 0.017453293\n",
    "\n",
    "cdef float deg2rad(float deg):\n",
    "    cdef float rad = deg * PI_RATIO\n",
    "    return rad\n",
    "    \n",
    "def cython_haversine(float lon1, float lat1, float lon2, float lat2):\n",
    "    cdef float rlon1 = deg2rad(lon1)\n",
    "    cdef float rlon2 = deg2rad(lon2)\n",
    "    cdef float rlat1 = deg2rad(lat1)\n",
    "    cdef float rlat2 = deg2rad(lat2)\n",
    "    \n",
    "    cdef float dlon = rlon2 - rlon1\n",
    "    cdef float dlat = rlat2 - rlat1\n",
    "\n",
    "    cdef float a = sin(dlat/2)**2 + cos(rlat1) * cos(rlat2) * sin(dlon/2)**2\n",
    "\n",
    "    cdef float c = 2 * asin(sqrt(a))\n",
    "    cdef float km = 6371 * c\n",
    "    return km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_loop_cython(coordinates: list) -> list:\n",
    "    distances = np.zeros(len(coordinates))\n",
    "    for i, row in enumerate(coordinates):\n",
    "        distance = cython_haversine(*row)\n",
    "        distances[i] = distance\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time distances = haversine_loop_python(df_coor.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time distances = haversine_loop_cython(df_coor.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time distances = haversine_loop_jit(df_coor.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Why isn't `haversine_loop_cython` faster than jit?**\n",
    "\n",
    "<details>\n",
    "  <summary markdown='span'>üéÅ Answer</summary>\n",
    "\n",
    "Because we have only coded the scalar function `cython_haversine` in C, not the whole haversine_loop.  \n",
    "\n",
    "@jit, on the other hand, has had the opportunity to \"see\" and optimize the whole outer-loop.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3Ô∏è‚É£ GPUs?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Open this notebook with [Google Colab](https://colab.research.google.com/), then and choose Runtime --> Runtime type: **GPU**\n",
    "\n",
    "We'll use Tensorflow to multiply matrices much faster than numpy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0HL2wNQaKUIy"
   },
   "source": [
    "You can manually select the processor on which to perform your tensor operations.\n",
    "\n",
    "‚è©‚è©‚è© Check out the [documentation](https://www.tensorflow.org/guide/gpu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FsmmanvtKUIy",
    "outputId": "c2634ebb-d44c-4fd5-d82d-241282327d0a"
   },
   "outputs": [],
   "source": [
    "# Check CPU's available\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viFY6VHhKUIz",
    "outputId": "0c73d688-4953-4619-d8ff-f3fad9c4b609"
   },
   "outputs": [],
   "source": [
    "# If you've set up Colab correctly, you should have a GPU avaiable.\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gbo9XVjNKUIz"
   },
   "outputs": [],
   "source": [
    "# Matrix multiplication function performing operation and returning us the time.\n",
    "import time\n",
    "\n",
    "def time_matmul(types,x):\n",
    "\n",
    "    start = time.time() \n",
    "\n",
    "    if types=='numpy':\n",
    "        np.matmul(x,x)\n",
    "\n",
    "    else:\n",
    "        tf.matmul(x,x)\n",
    "\n",
    "    diff = time.time() - start\n",
    "\n",
    "    return diff*1000\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Run this cell twice (the first time it runs, tensorflow compilation for GPU takes a bit of time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lKrfs0uoKUIz",
    "outputId": "ee475c1d-5f9b-42da-af61-f16b33d3d3f7"
   },
   "outputs": [],
   "source": [
    "shape_dim = []\n",
    "num_time = []\n",
    "cpu_tf_time = []\n",
    "gpu_tf_time = []\n",
    "\n",
    "for shape in range(500,2001,100):\n",
    "\n",
    "    print(f\"Multiplication of shape [{shape},{shape}]\")\n",
    "\n",
    "  # Start with shape 500,500 to 2000,2000 with an increase of 100\n",
    "    shape_dim.append(shape)\n",
    "\n",
    "  # Numpy multiplication\n",
    "    x_np = np.random.uniform(size=[shape,shape])\n",
    "    num_time.append(time_matmul('numpy',x_np))\n",
    "  \n",
    "  #Tensor in CPU\n",
    "    with tf.device(\"CPU:0\"):\n",
    "        x = tf.random.uniform([shape, shape])\n",
    "        cpu_tf_time.append(time_matmul('cpu',x))\n",
    "        \n",
    "  #Tensor in GPU multiplication\n",
    "    with tf.device(\"GPU:0\"): #Or GPU:1 for the 2nd GPU, GPU:2 for the 3rd etc.\n",
    "        x = tf.random.uniform([shape, shape])\n",
    "        gpu_tf_time.append(time_matmul('gpu',x))\n",
    "\n",
    "print(\"Done multiplying!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "t5Q604iCKUIz",
    "outputId": "d53b098d-f6a6-40c7-f510-fcb511bc585f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(shape_dim, num_time, label=\"Numpy Array\")\n",
    "plt.plot(shape_dim, cpu_tf_time, label=\"Tensor in CPU\")\n",
    "plt.plot(shape_dim, gpu_tf_time, label=\"Tensor in GPU\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Shape of the Matrix\")\n",
    "plt.ylabel(\"Time in milliseconds\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
