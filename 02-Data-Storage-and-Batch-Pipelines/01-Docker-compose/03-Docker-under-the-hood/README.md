# Docker under the hood

This exercise will try and take some of the magic away from containers and guide you through creating a python script which creates your own fully isolated Ubuntu container!

🎯 By the end you should be able to use your script to enter a isolated `bash` shell in a new independent file system with all the required files for ubuntu!

## 1️⃣ Starting our project

Same workflow as usual with poetry so we have somewhere to install packages. We don't want to hook into poetry for reasons that will be demonstrated later so when you need to run just use `poetry run`! Here the only non standard library package we will be using for this exercise is `requests`!

## 2️⃣ Getting ubuntu

To start our container off we are going to stick to ubuntu for simplicity but you could extend what we do here to fetch any of the files for any container on Docker Hub.

❓ Our goal is to hook into the [docker api](https://docs.docker.com/registry/spec/api/) and extract the files into a target folder. This should be done in `main.py` by `extract_ubuntu` - a function which takes in a path generated by `pathlib.Path` and then outputs ubuntu into that directory.

The pseudo-code is as follows:

```python
1.
Call the docker token api(https://auth.docker.io/token) and get a token
2.
Get manifest for ubuntu from the registry api using the token
3.
Get layer for ubuntu from the https://auth.docker.io/token
4.
extract into the given folder
```

🤯 Warning doing this from scratch will take a while. Consider this optional and just copy the hints and move on unless you really want to challenge your API skills.

<details>
<summary markdown='span'>Token API link</summary>

```
https://auth.docker.io/token?service=registry.docker.io&scope=repository:library/ubuntu:pull&client_id=ogiles1999
```
</details>

<details>
<summary markdown='span'>Manifest API link</summary>

```
https://registry-1.docker.io/v2/library/ubuntu/manifests/latest
```
with a header including
```
Authorization: bearer <your_token>
```
</details>

<details>
<summary markdown='span'>Layer API link</summary>

```
https://registry-1.docker.io/v2/library/ubuntu/blobs/<sha from manifest>
```
</details>

<details>
<summary markdown='span'>Extraction command</summary>

```bash
tar -xf <your_file.tar>
```
</details>

<details>
<summary markdown='span'>💡 Full code in Python</summary>

```python
import requests
import pathlib

def get_ubuntu(path: pathlib.PosixPath) -> None:
    params = {
        "service": "registry.docker.io",
        "scope": "repository:library/ubuntu:pull",
        "client_id": "ogiles1999"
    }

    token = requests.get("https://auth.docker.io/token",
                         params=params).json()["token"]

    headers = {"Authorization": "bearer " + token}

    man_url = "https://registry-1.docker.io/v2/library/ubuntu/manifests/latest"

    sha = requests.get(man_url, headers=headers).json()
    sha = sha["fsLayers"][-1]["blobSum"]

    with open(path.joinpath("ubuntu.tar"), "wb") as file:
        base = "https://registry-1.docker.io/v2/library/ubuntu/blobs/"
        response = requests.get(base + sha,
                                headers=headers)
        file.write(response.content)

    subprocess.run(["tar", "-xf", "ubuntu.tar"], cwd=path)
```

</details>


<br/>

❓ Now lets test your function! Create a folder and add a call to `get_ubuntu` in the `__main__` block to the end of your
file to run the extraction by running the script!

```bash
mkdir test_folder
```

```python
if __name__ == "__main__":
    get_ubuntu(pathlib.Path("test_folder"))
```

```bash
poetry run pyocker/main.py
```

If your ubuntu function is working properly when you run `ls test_folder` you
should see the following:
![ubuntu folders](https://wagon-public-datasets.s3.amazonaws.com/data-engineering/W1D1/extracted-ubuntu.png)

You can also add a call to cleanup the `ubuntu.tar` but it is not necessary as our next section will **deal with the cleanup for us!**

<br>

## 3️⃣ Temporary directory

Now we have the files we need, lets also create somewhere to put those files. We don't want to have to manage creating and cleaning up lots of folders ourselves so lets use the inbuilt [tempfile](https://docs.python.org/3/library/tempfile.html) module!

❓ In the `main.py` module, add code which creates and cleans up temporary directory. Then inside this temporary directory use `get_ubuntu` to extract ubuntu files into the temporary directory.

<details>
<summary markdown='span'>💡 If you get stuck</summary>

Use a context manager to deal with cleanup!
```python
import tempfile
import pathlib

def run(arg: str) -> None:
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_dir_path = pathlib.Path(temp_dir)

        get_ubuntu(temp_dir_path)
```

</details>

Now we have a folder with all of the files we need in order to run Ubuntu OS in an isolated container. 🚚

There are a lot of layers of isolation that we would need in order to fully comply with the [OCI standard](https://opencontainers.org/), but lets focus on the main ones:

- Restricted memory without having a hypervisor completely sectioning off memory (like we would have on a virtual machine).
- Isolated file system.
- Isolated processes (i.e. the container can't see the processes occurring on the rest of the machine!)
- Fully functional (i.e. Linux is fully functional within the bounds of the container!)

Lets do this step by step! 🧗


## 4️⃣ Isolated file system

### 4.1 Startup script
Next we need to work on isolating our file system. 🗄️

Here we are going to go with the 'naive' approach of using [`chroot`](https://wiki.archlinux.org/title/chroot)!

We want to execute a few terminal commands on the startup of our container. Python does not necessarily have the best interface to run lots of terminal commands as single process. 🙅‍♂️ To get around this, we can create a `.sh` script with Python and then execute that!

🎯 In your `run` function create a `startup.sh` script that just runs the `arg` passed to the function as a string. Then make the script executable and put it in our temporary directory.

<details>
<summary markdown='span'>💡 If you get stuck</summary>

```bash
with open("startup.sh", "w") as f:
    f.writelines([
        "#!/bin/bash\n",
        "hostname pyocker\n"
        "mount -t proc proc /proc\n",
        arg
    ])
subprocess.run(["sudo", "chmod", "+x", "startup.sh"])
subprocess.run(["mv", "startup.sh", temp_dir_path])
```
</details>

### 4.2 Chroot 📍

Next we want to work on making the root of our container's file system at our temporary directory.

❓ Now we have our script in the temporary directory, move into the temp directory and run `chroot`, plus our terminal command (you will need to run the Python script as root to make it work 😅)!

Don't forget to update the `__main__` block as well to use `run` write the command, `arg`, passed as an argument or read it from `sys.argv[1]`.

❗️ The behavior we hope to see is that when running our script with argument `pwd`, it should return `/`!

<details>
<summary markdown='span'>💡 If you get stuck with `chroot` in the Python script</summary>

```bash
os.chdir(temp_dir_path)
subprocess.run(["unshare","-mpfu","chroot", temp_dir_path, "./startup.sh"])
```

</details>

<details>
<summary markdown='span'>💡 If you get stuck running the script as `root` on your machine</summary>

```bash
sudo $(poetry env info -p)/bin/python pyocker/main.py pwd # if you used sys.argv in your Python script, otherwise without 'pwd'
```
</details>

Now you should be able to run `pyocker/main.py` with `ls` or `pwd` and see your isolated file system!

### 4.3 Cleaning up the process 🧹

Now if you run your script with `/bin/bash` instead you can explore your container! You can notice one issue here the hostname is still the same which might not be ideal.

Also try and run your `run` function with `ps` - you should see a command `mount -t proc proc /proc`. **Run this** and run `ps -aux` it will now work but you can also see all the processes on the rest of your machine so we need to remove that!

Before we remove the view of the other processes lets add two more lines to our startup script

```bash
hostname pyocker
mount -t proc proc
```

We are now ready to isolate the processes. For now when shutting down your container you will get an error you can ignore that for now!

## 5️⃣ Isolating the process 🥷

The final step we are going to cover is about isolating the process from the rest of the processes on the system.

Here we just need to use the [unshare](https://man7.org/linux/man-pages/man1/unshare.1.html) command to unshare the the PID namespace!

Lets just unshare the `pid`, `user`, and mount to make it as simple as possible (still quite difficult)!

❓ You need to find the correct command and prepend it to our `chroot` call!

<details>
<summary markdown='span'>💡 If you get stuck!</summary>

```bash
unshare -mpfu chroot
```

</details>

❗️ Now if you enter the container and run `ps -aux` process 1 should be our startup script. We have isolated the process so it cannot see anything else running on our machine!

## 6️⃣ Putting it all together 🎁

🏁 We can now run:

```bash
sudo $(poetry env info -p)/bin/python pyocker/main.py /bin/bash # run("/bin/bash") inside main.py
```

Giving us a container running with our created `cgroup`, with a new file system, and isolated PID! 🙌

## 7️⃣ Still to do 😅

This is a pretty great level of isolation, especially for one exercise but there are a few things still to do if we wanted to take it further.

- Make a command to run our now quite long and ugly command!
- Networking for the container.
- Isolation of all the groups.
- Setup the `cgroup` to restrict how much memory the container uses.
- Chroot is slightly `naive` and you can break out of it (you can instead use a more advanced tool like [firejail](https://firejail.wordpress.com/)).
- Setup a union file system ([read more here](https://martinheinz.dev/blog/44)). At the moment each container takes up the space of the `ubuntu.tar` on memory!

## Congrats on finishing this optional challenge! 🏋️‍♂️
