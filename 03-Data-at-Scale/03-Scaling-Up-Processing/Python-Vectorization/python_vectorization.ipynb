{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1Ô∏è‚É£ Vectorize \"easy\" operations with pandas and numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Vectorized-addition.gif/220px-Vectorized-addition.gif'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 5000\n",
    "n_cols = 5000\n",
    "a = np.random.randint(low=0, high=5, size=(n_rows,n_cols), dtype=np.int64)\n",
    "df = pd.DataFrame(a)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider different methods for summing all elements of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Worse case scenario: double python for loop (O(n^2)) !!\n",
    "sum = 0\n",
    "for row_id in range(n_rows):\n",
    "    for el in a[row_id,:]:\n",
    "        sum = sum + el\n",
    "sum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Column-wise operation (axis=0): Apply np.sum 5000 times for each columns, then apply np.sum one last time to get the final result!\n",
    "np.apply_along_axis(np.sum, 0, a).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Row-wise operation (axis=1): Apply np.sum 5000 times for rows columns, then apply np.sum one last time to get the final result!\n",
    "np.apply_along_axis(np.sum, 1, a).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è Numpy is row-major (by default). Avoid iterating on its columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://craftofcoding.files.wordpress.com/2017/02/rowcolumnarrays.jpg?w=620&h=356'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, we can change its numpy's storage format from row to columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "a           = np.ones((n_rows,n_cols), order='C') # C-style BY DEFAULT\n",
    "a_col_major = np.ones((n_rows,n_cols), order='F') # F for Fortran style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Column-wise operation\n",
    "np.apply_along_axis(np.sum, 0, a_col_major).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Row-wise operation\n",
    "np.apply_along_axis(np.sum, 1, a_col_major).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2)üêº Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Using pandas vectorized sum is much faster (here, it is called n_cols + 1 times)\n",
    "df.sum().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è**Pandas is column-major**. **Avoid iterating manually on its rows** (convert to numpy which is row-major if needs be)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column named \"0\", 1000 times\n",
    "%timeit -n1000 df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first ROW, 1000 times\n",
    "%timeit -n1000 df.iloc[0,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) What about more complex operations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "A_list = np.random.randint(0, 4, N)\n",
    "B_list = np.random.randint(0, 4, N)\n",
    "df = pd.DataFrame({'A': A_list, 'B': B_list})\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we want to do divide col \"A\" by col \"B\" in the following matrix, but without any `NaN`  \n",
    "\n",
    "Remember, in numpy\n",
    "- `1./0. == np.inf` ‚úÖ\n",
    "- but `0./0. == np.nan` üò∞\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# This would be super fast but it's not what we want!\n",
    "_ = df['A']/df['B']\n",
    "_.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define our custom division function\n",
    "\n",
    "def divide_without_nan(row):\n",
    "    if row[0] == row[1]:\n",
    "        return 1\n",
    "    return float(row[0]/row[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could \"apply\" on each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new = df.apply(lambda row: divide_without_nan(row), axis=1)\n",
    "assert new.isna().sum() == 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Remember, we need to try to avoid looping over pandas rows.\n",
    "\n",
    "‚ùì**Try to make it faster by converting to it to numpy first** (which is row-major), then use `np.apply_along_axis()`!\n",
    "You should find it's about 4 time faster!\n",
    "\n",
    "<details>\n",
    "  <summary markdown='span'>üéÅ Solution</summary>\n",
    "\n",
    "```python\n",
    "%%time\n",
    "new = np.apply_along_axis(divide_without_nan, 1, df.values)\n",
    "assert np.isnan(new).sum() == 0\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are still very very far from the purely \"vectorized\" speed offered by C-based numpy/pandas operation!  \n",
    "‚ùì **Can you find a way to make this computation fully vectorized ?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary markdown='span'>üí°Hints</summary>\n",
    "\n",
    "`np.where()`\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2Ô∏è‚É£ When you can't find \"vectorized\" numpy equivalents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://wagon-public-datasets.s3.amazonaws.com/taxi-fare-ny/train_500k.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, asin, sqrt\n",
    "EARTH_RADIUS = 6371\n",
    "\n",
    "def haversine(lon1: float,lat1: float,lon2: float,lat2: float) -> float:\n",
    "    \"\"\"returns the geodistance in km between two tuple of coordinates\"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    return 2 * EARTH_RADIUS * asin(sqrt(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Baseline score: python loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "distances = df.apply(lambda row: haversine(row[\"pickup_longitude\"], row[\"pickup_latitude\"], row[\"dropoff_longitude\"], row[\"dropoff_latitude\"]), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üòµ What did we just do! Iterating on DataFrame by rows is a very bad practice...\n",
    "\n",
    "üëá We can do a bit better by transposing dataframe and iterate on its **columns**..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_coor = df[[\"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"]]\n",
    "distances = df_coor.T.apply(lambda col: haversine(*col), axis=0, raw=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we're still applying a non-vectorized lambda function, so pandas/numpy are not helping at all!\n",
    "\n",
    "Let's get rid of pandas and numpy overhead altogether and see what happens in pure python..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_loop_python(coordinates: list) -> list:\n",
    "    distances = np.zeros(len(coordinates))\n",
    "    for i, row in enumerate(coordinates):\n",
    "        distance = haversine(*row)\n",
    "        distances[i] = distance\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time distances = haversine_loop_python(list(df_coor.values))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Better, but still way too long! Basically, **a for loop in python is almost always sub-optimal**\n",
    "\n",
    "Let's vectorize this code!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Numba"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first option: `jit` your outer python loop directly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have a particular function to optimize, but a whole code block with python loops, you can use `@jit` to let numba try to create a optimized version of your whole code block the first time it runs. Then, all subsquent runs will be vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def haversine_loop_jit(coordinates):\n",
    "    distances = np.zeros(len(coordinates))\n",
    "    for i, row in enumerate(coordinates):\n",
    "        lon1, lat1, lon2, lat2 = map(radians, [row[0], row[1], row[2], row[3]])\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "        a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "        distance = 2 * EARTH_RADIUS * asin(sqrt(a))\n",
    "        distances[i] = distance\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this twice\n",
    "%time distances = haversine_loop_jit(df_coor.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Amazing, isn't it! Another 10x improvement here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### second option: `vectorize` your inner scalar computation, then call it with numpy arrays instead of scalars!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntax is simply \n",
    "\n",
    "```python\n",
    "@vectorize([output_type(arg1_type, arg2_type...)])\n",
    "def my_vectorized_python_function(arg1, arg2..):\n",
    "    pass\n",
    "```\n",
    "‚òùÔ∏è You just have to specify to numby what are the input and output type you expect, and the **new function can now take iterables** like pd.Series or np.ndarray instead of scalar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import vectorize, float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize([float64(float64, float64, float64, float64)])\n",
    "def vectorized_haversine(lon1,lat1,lon2,lat2):\n",
    "    \"\"\"returns the geodistance in km between two tuple of coordinates\"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    return 2 * EARTH_RADIUS * asin(sqrt(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell twice to see best speed performance\n",
    "%time distances = vectorized_haversine(df[\"pickup_longitude\"], df[\"pickup_latitude\"], df[\"dropoff_longitude\"], df[\"dropoff_latitude\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you had multiple CPUs or GPUs, you could go even faster with \n",
    "\n",
    "```python\n",
    "@vectorize(target=\"parallel\") # Multi-core CPU\n",
    "@vectorize(target=\"CUDA\") # GPU acceleration\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üì∫ If you are not convinced yet, take 5min to see [this real-world example](https://youtu.be/x58W9A2lnQc?t=719) on youtube"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) Cython"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you know how to write C, you can also code your own vectorized function using Cython. The goal is to minimize the amount of \"python\" code (in yellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "\n",
    "from libc.math cimport sin, cos, asin, sqrt\n",
    "   \n",
    "## Equivalent to 3.1415927 / 180\n",
    "cdef float PI_RATIO = 0.017453293\n",
    "\n",
    "cdef float deg2rad(float deg):\n",
    "    cdef float rad = deg * PI_RATIO\n",
    "    return rad\n",
    "    \n",
    "def cython_haversine(float lon1, float lat1, float lon2, float lat2):\n",
    "    cdef float rlon1 = deg2rad(lon1)\n",
    "    cdef float rlon2 = deg2rad(lon2)\n",
    "    cdef float rlat1 = deg2rad(lat1)\n",
    "    cdef float rlat2 = deg2rad(lat2)\n",
    "    \n",
    "    cdef float dlon = rlon2 - rlon1\n",
    "    cdef float dlat = rlat2 - rlat1\n",
    "\n",
    "    cdef float a = sin(dlat/2)**2 + cos(rlat1) * cos(rlat2) * sin(dlon/2)**2\n",
    "\n",
    "    cdef float c = 2 * asin(sqrt(a))\n",
    "    cdef float km = 6371 * c\n",
    "    return km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_loop_cython(coordinates: list) -> list:\n",
    "    distances = np.zeros(len(coordinates))\n",
    "    for i, row in enumerate(coordinates):\n",
    "        distance = cython_haversine(*row)\n",
    "        distances[i] = distance\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time distances = haversine_loop_python(df_coor.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time distances = haversine_loop_cython(df_coor.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time distances = haversine_loop_jit(df_coor.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Why isn't `haversine_loop_cython` the faste than cython?**\n",
    "\n",
    "<details>\n",
    "  <summary markdown='span'>üéÅ Answer</summary>\n",
    "\n",
    "Because we have only coded the scalar function `cython_haversine` in C, not the whole haversine_loop.  \n",
    "\n",
    "@jit, on the other hand, has had the opportunity to \"see\" and optimize the whole outer-loop.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.14 64-bit ('3.8.14')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42ec3ba9710b441755cff7720f578411a6d27c746638d35edd32dd70fa8218bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
